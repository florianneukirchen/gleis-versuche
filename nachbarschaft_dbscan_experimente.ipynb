{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimente mit DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdal \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "import scipy.sparse as sp\n",
    "import os\n",
    "import json\n",
    "import pyvista as pv\n",
    "\n",
    "\n",
    "from interessant import * # Bei Änderungen Kernel neu starten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weiche B 4479025_5352925.copc.laz\n"
     ]
    }
   ],
   "source": [
    "run = run24\n",
    "#run = run14\n",
    "# filename = interessant['OLA gleiche Höhe wie Gleis']\n",
    "\n",
    "# Bahnsteig: 29; Gleis hohe Intensität: 11; Weiche B: 16; Unterirdischer Bhf: 20; Gleis weit abseits: 23; Betondeckel: 28; Zug run 14 A (in run24 Achszähler): 6; \n",
    "# Viele Gleise: 33; Anfang Weiche: 34; Weiche C: 38 OLA gleiche H: 35; Y: 37\n",
    "key = list(interessant.keys())[16] \n",
    "filename = interessant[key]\n",
    "print(key, filename)\n",
    "\n",
    "filename = os.path.join(run, filename)\n",
    "if not os.path.exists(filename):\n",
    "    raise FileNotFoundError(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel size: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "thresh = 8  # z.B. 5 oder 8\n",
    "majority_tresh  = 0.5 # Erster Durchgang 0.3, bei \"Gleis hohe Intensität\" gibt 0.5 ein viel besseres Ergebnis\n",
    "\n",
    "voxel_size = 1.0\n",
    "\n",
    "voxel_size = 25 / 30\n",
    "print(\"Voxel size:\", voxel_size)\n",
    "\n",
    "minimum_points = 50 # Erste Versuche mit 100, aber viel schwarz bei abseits liegenden Gleisen. 50 ist besser.\n",
    "minimum_in_hood = 10\n",
    "linearity_tresh = 0.98\n",
    "\n",
    "intensity_threshold = 14500\n",
    "downsample_radius = 0.3\n",
    "neighborhood_radius = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['pyvistaviewer', '/media/riannek/minimax/gle...>"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "# subprocess.Popen([\"pyvistaviewer\", filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(filename='dbscan.log', encoding='utf-8', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voxelfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pdal.Pipeline([pdal.Reader(filename)])\n",
    "pipeline.execute()\n",
    "points = pipeline.arrays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = np.vstack((points['X'], points['Y'], points['Z'])).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offset entfernen (aber gerundet, damit Kachelgrenzen ganze Zahlen bleiben)\n",
    "offset = xyz.mean(axis=0).round() \n",
    "# xyz -= offset   # Nur für Visualisierung benötigt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "points['Classification'] = 0 # Unclassified\n",
    "RAIL = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.47905000e+06, 5.35295000e+06, 4.68263895e+02]),\n",
       " array([4.47902500e+06, 5.35292500e+06, 4.60171095e+02]))"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxp = xyz.max(axis=0)\n",
    "minp = xyz.min(axis=0)\n",
    "maxp, minp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /media/riannek/minimax/gleis/2024-08-13/01/run24/01/4479025_5352925.copc.laz\n"
     ]
    }
   ],
   "source": [
    "voxels = xyz.copy()\n",
    "voxels[:, :2] = ((xyz[:, :2] - minp[:2]) // voxel_size).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 30])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anzahl der Voxel checken\n",
    "np.ceil((maxp[:2] - minp[:2]) / voxel_size).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press \"M\" to toggle between Intensity, RGB, and Classification modes\n",
      "Press \"Left\" and \"Right\" arrow keys to rotate the point cloud around Z-axis\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "voxel_dict = defaultdict(list)\n",
    "index_dict = defaultdict(list)\n",
    "\n",
    "# Füllen des Dictionaries\n",
    "for idx, (point, voxel) in enumerate(zip(xyz, voxels)):\n",
    "    voxel_key = tuple(voxel[:2])\n",
    "    voxel_dict[voxel_key].append(point[2])\n",
    "    index_dict[voxel_key].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, z_values in voxel_dict.items():\n",
    "    \n",
    "    # Threshold on number of points in voxel\n",
    "    if len(z_values) < minimum_points:\n",
    "        continue\n",
    "\n",
    "    indices = np.array(index_dict[key])\n",
    "    z_values = np.array(z_values)\n",
    "    ground_level = np.percentile(z_values, 10) # 10% Percentile\n",
    "    # Check that there are almost no points 0.5 to 4.5 m above the ground\n",
    "    # But allow for some noise\n",
    "    # thresh = 3 # Der einfachheit halber oben\n",
    "    count = ((z_values > ground_level + 0.5) & (z_values < ground_level + 4.5)).sum()\n",
    "\n",
    "    if count <= thresh:\n",
    "        # Look for points within 0.5 m above ground and get 98% percentile ODER 99.5\n",
    "        mask = (z_values > ground_level) & (z_values < ground_level + 0.5)\n",
    "        try:\n",
    "            candidates_top = np.percentile(z_values[mask], 99.5)\n",
    "        except IndexError:\n",
    "            # Fails if there are no points in the masked array\n",
    "            continue\n",
    "\n",
    "        # Oude Elberink require the height difference > 0.1 m\n",
    "        # And mark only the points 10 cm below the top as rail point candidates\n",
    "        if candidates_top - ground_level > 0.1:\n",
    "            mask = (z_values > candidates_top - 0.1) & (z_values < candidates_top + 0.05)\n",
    "\n",
    "            # Also make sure these are only a minority of the points (otherwise it's a slope)\n",
    "            if mask.sum() < majority_tresh * len(z_values):  # z.B. 0.3\n",
    "                points['Classification'][indices[mask]] = RAIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93165,)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = points[points[\"Classification\"] == RAIL]\n",
    "candidates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"type\": \"filters.outlier\", \"method\": \"statistical\", \"mean_k\": 10, \"multiplier\": 2.0, \"tag\": \"filters_outlier1\"}, {\"type\": \"filters.range\", \"limits\": \"Classification![7:7]\", \"tag\": \"filters_range1\"}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(90623,)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filters.outlier sets Classification to 7, filters.range removes the points with Classification 7\n",
    "\n",
    "noise_filter = pdal.Filter(\"filters.outlier\", method=\"statistical\", mean_k=10, multiplier=2.0).pipeline(candidates) | pdal.Filter(\"filters.range\", limits=\"Classification![7:7]\")\n",
    "print(noise_filter.toJSON())\n",
    "noise_filter.execute()\n",
    "candidates = noise_filter.arrays[0]\n",
    "candidates.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewsettings mit strg + c kopieren und hier einfügen\n",
    "\n",
    "viewsettings = '''\n",
    "{\n",
    "\t\"class_name\" : \"ViewTrajectory\",\n",
    "\t\"interval\" : 29,\n",
    "\t\"is_loop\" : false,\n",
    "\t\"trajectory\" : \n",
    "\t[\n",
    "\t\t{\n",
    "\t\t\t\"boundingbox_max\" : [ 11.999975427985191, 11.99998692702502, 13.124079998226534 ],\n",
    "\t\t\t\"boundingbox_min\" : [ -13.000024572014809, -13.00001307297498, -3.9965200017734333 ],\n",
    "\t\t\t\"field_of_view\" : 60.0,\n",
    "\t\t\t\"front\" : [ -0.20468464372193082, -0.82045900926496551, 0.53380821531742795 ],\n",
    "\t\t\t\"lookat\" : [ -2.1145501200370735, -2.6052610037108783, 1.4494799802055294 ],\n",
    "\t\t\t\"up\" : [ 0.19010212482081987, 0.50164960558000959, 0.84392467398461002 ],\n",
    "\t\t\t\"zoom\" : 0.55999999999999983\n",
    "\t\t}\n",
    "\t],\n",
    "\t\"version_major\" : 1,\n",
    "\t\"version_minor\" : 0\n",
    "}\n",
    "\n",
    "'''\n",
    "\n",
    "viewsettings = json.loads(viewsettings)\n",
    "\n",
    "front = viewsettings[\"trajectory\"][0][\"front\"]\n",
    "lookat = viewsettings[\"trajectory\"][0][\"lookat\"]\n",
    "up = viewsettings[\"trajectory\"][0][\"up\"]\n",
    "zoom = viewsettings[\"trajectory\"][0][\"zoom\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate and Seed Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = np.vstack((candidates['X'], candidates['Y'], candidates['Z'])).transpose()\n",
    "xyz -= offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65265,)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_intensity = candidates[candidates[\"Intensity\"] < intensity_threshold]\n",
    "low_intensity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445,)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample with poisson sampling\n",
    "\n",
    "downsampling_pipeline = pdal.Filter(\"filters.sample\", radius=downsample_radius).pipeline(low_intensity)\n",
    "downsampling_pipeline.execute()\n",
    "seed_points = downsampling_pipeline.arrays[0]\n",
    "seed_points.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_seed = np.vstack((seed_points['X'], seed_points['Y'], seed_points['Z'])).transpose()\n",
    "xyz_seed -= offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-D tree with all candidate points\n",
    "tree = KDTree(xyz)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices: ndarray (dtype object) with a list of indices for each seed point\n",
    "indices = tree.query_ball_point(xyz_seed, r=neighborhood_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_point_count = xyz_seed.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(cloud):\n",
    "    \"\"\"Use PCA to get einvalues and eigenvectors of a point cloud\"\"\"\n",
    "    mean = np.mean(cloud, axis=0)\n",
    "    centered = cloud - mean\n",
    "    cov_matrix = np.cov(centered, rowvar=False) # row variance nicht berechnen\n",
    "    eigenvals, eigenvecs = np.linalg.eig(cov_matrix)\n",
    "    sorted_indices = np.argsort(eigenvals)[::-1]\n",
    "    sorted_eigenvals = eigenvals[sorted_indices]\n",
    "    sorted_eigenvecs = eigenvecs[:,sorted_indices]\n",
    "    return sorted_eigenvals, sorted_eigenvecs\n",
    "\n",
    "def linearity(eigenvals):\n",
    "    \"\"\"Calculate the linearity of a point cloud\"\"\"\n",
    "    return (eigenvals[0] - eigenvals[1]) / eigenvals[0]\n",
    "\n",
    "def pca_spread(points, eigenvals, eigenvects):\n",
    "    \"\"\"Length along first principal component\"\"\"\n",
    "    projected = points @ eigenvects[:,0] # Project on first eigenvector\n",
    "    return (np.max(projected) - np.min(projected)) * np.sqrt(eigenvals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta(eigenvects):\n",
    "    \"\"\"Angle between the first eigenvector and the z-axis\"\"\"\n",
    "    cos_theta = eigenvects.T[0] @ np.array([0, 0, 1]) / np.linalg.norm(eigenvects[0]) # / np.linalg.norm(eigenvects[0]) unnötig, Vektor hat Länge 1\n",
    "    return np.arccos(cos_theta) * 180 / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan(xyz, eps=0.05, min_points=10):\n",
    "    hood_pcd = o3d.geometry.PointCloud()\n",
    "    hood_pcd.points = o3d.utility.Vector3dVector(xyz) \n",
    "    # eps is min distance between clusters\n",
    "    labels = np.array(hood_pcd.cluster_dbscan(eps=eps, min_points=min_points, print_progress=False))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan_stretchz(xyz, eps=0.05, min_points=10, stretch=1.5):\n",
    "    xyz = xyz.copy()\n",
    "    xyz[:, 2] *= stretch\n",
    "    hood_pcd = o3d.geometry.PointCloud()\n",
    "    hood_pcd.points = o3d.utility.Vector3dVector(xyz) \n",
    "    # eps is min distance between clusters\n",
    "    labels = np.array(hood_pcd.cluster_dbscan(eps=eps, min_points=min_points, print_progress=False))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan_stretchz_auto(xyz, min_points=10, stretch=1.5):\n",
    "\n",
    "    pointcount = xyz.shape[0]\n",
    "    if pointcount <= min_points:\n",
    "        return np.ones(pointcount, dtype=np.int8) * -1\n",
    "    \n",
    "    eps = 50 / pointcount\n",
    "    eps = max(eps, 0.06)\n",
    "    \n",
    "    xyz = xyz.copy()\n",
    "    xyz[:, 2] *= stretch\n",
    "    hood_pcd = o3d.geometry.PointCloud()\n",
    "    hood_pcd.points = o3d.utility.Vector3dVector(xyz) \n",
    "    # eps is min distance between clusters\n",
    "    labels = np.array(hood_pcd.cluster_dbscan(eps=eps, min_points=min_points, print_progress=False))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def graph_based_segmentation(points, max_distance=0.1):\n",
    "#     kdtree = KDTree(points)\n",
    "#     graph = kdtree.sparse_distance_matrix(kdtree, max_distance=max_distance)\n",
    "\n",
    "#     n_components, labels = connected_components(graph, directed=False)\n",
    "\n",
    "#     return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktioniert nicht, 0 Cluster gefunden\n",
    "\n",
    "# def dbscan_stretchz_pdal(xyz, eps=0.07, min_points=20, stretch=1.5):\n",
    "#     xyz = xyz.copy()\n",
    "#     xyz[:, 2] *= stretch\n",
    "\n",
    "#     dt = {'names': ['X', 'Y', 'Z'], 'formats': [np.float32, np.float32, np.float32]}\n",
    "#     pipeline = pdal.Filter(type=\"filters.dbscan\", min_points=20, eps=0.07).pipeline(xyz.view(dt))\n",
    "    \n",
    "#     pipeline.execute()\n",
    "#     return pipeline.arrays[0]['ClusterID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_points = 10\n",
    "minimum_in_hood = 10\n",
    "linearity_tresh = 0.98 # 0.98\n",
    "\n",
    "with_lines = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_line(cluster, eigenvects, stretch=0.2):\n",
    "    start = cluster.mean(axis=0)\n",
    "    vector = eigenvects.T[0] * stretch\n",
    "    end = start + vector\n",
    "    line = pv.Line(start, end)\n",
    "\n",
    "    return line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "linearity_at_seed = np.empty((seed_point_count,1), dtype=float)\n",
    "linearity_at_seed[:,:] = np.nan\n",
    "trackcount = np.zeros((seed_point_count,1), dtype=int)\n",
    "clustercount = np.zeros((seed_point_count,1), dtype=int)\n",
    "\n",
    "lines = []\n",
    "\n",
    "for i in range(seed_point_count):\n",
    "    hood = xyz[indices[i]]\n",
    "    if hood.shape[0] < minimum_in_hood:   \n",
    "        continue\n",
    "    logger.debug(\"--------------------------\")\n",
    "    logger.debug(f\"Seed point {i} has {hood.shape[0]} points in its neighborhood\")\n",
    "\n",
    "    # DBSCAN with stretched z\n",
    "    # labels = dbscan_stretchz(hood, eps=2, min_points=min_points, stretch=4) # Weiche C funktioniert eps=0.07, min_points=20, stretch=4\n",
    "    labels = dbscan_stretchz_auto(hood, min_points=min_points, stretch=4)\n",
    "    max_label = labels.max()\n",
    "    clustercount[i] = max_label + 1\n",
    "    logger.debug(f\"DBSCAN {max_label + 1} clusters\")\n",
    "    # print(max_label + 1, \"Clusters\")\n",
    "    for label in range(max_label + 1):\n",
    "        cluster = hood[labels == label]\n",
    "        try:\n",
    "            eigenvals, eigenvects = pca(cluster)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Rare cases of 0 points in cluster\n",
    "            continue\n",
    "        cluster_linearity = linearity(eigenvals)\n",
    "\n",
    "        # print(cluster_linearity, end=\" \")\n",
    "        logger.debug(f\"Cluster {label} linearity: {cluster_linearity}\")\n",
    "        logger.debug(f\"Eigenvalues: {eigenvals}\")\n",
    "        logger.debug(f\"Eigenvectors: {eigenvects}\")\n",
    "\n",
    "        \n",
    "        if (cluster_linearity > linearity_tresh) and (eigenvals[0] > 0.02):\n",
    "            # eigenvals[0] ist variance in 1. PC, also abhängig von der Länge\n",
    "            trackcount[i] += 1\n",
    "            if with_lines:\n",
    "                line = plot_cluster_line(cluster, eigenvects)\n",
    "                lines.append(line)\n",
    "    # print(\"\\nTrack count\", trackcount[i])\n",
    "    logger.debug(f\"Track count: {trackcount[i]}\")\n",
    "    # print()\n",
    "\n",
    "print(trackcount.max())\n",
    "print(clustercount.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kononenFullyAutomatedExtraction2024 verwenden threshold 0.98 (behalten aber zusätzlich auch Punkte in Nachbarschaften mit hoher Punktdichte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8487a21be9114094890e14bdb43124f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:37637/index.html?ui=P_0x7f969d7e7940_13&reconnect=auto\" class=\"pyv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use pyvista to get scalar colors with color bar\n",
    "pcd_hood = pv.PolyData(xyz_seed)\n",
    "pcd_hood[\"trackcount\"] = trackcount\n",
    "pcd_hood[\"clustercount\"] = clustercount\n",
    "\n",
    "# pv.plot(pcd_hood, scalars='trackcount', \n",
    "#         render_points_as_spheres=True, point_size=10,\n",
    "#         show_scalar_bar=True,\n",
    "#         )\n",
    "\n",
    "\n",
    "p = pv.Plotter()\n",
    "\n",
    "if with_lines:\n",
    "    # Add lines (SLOW)\n",
    "    for line in lines:\n",
    "        p.add_mesh(line, color='red')\n",
    "\n",
    "\n",
    "p.add_mesh_threshold(pcd_hood, 'trackcount', all_scalars=True, render_points_as_spheres=True, point_size=10)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_first_eigenvec(point, eigenvects, color=[1, 0, 0], stretch=1):\n",
    "    \"\"\"Plot a vector as a line\"\"\"\n",
    "    vector = eigenvects.T[0] * stretch\n",
    "    end = point + vector\n",
    "    line = o3d.geometry.LineSet()\n",
    "    line.points = o3d.utility.Vector3dVector([point, end])\n",
    "    line.lines = o3d.utility.Vector2iVector([[0, 1]])\n",
    "    line.colors = o3d.utility.Vector3dVector([color])\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed point 40 has 20 points in its neighborhood\n",
      "\n",
      "Found 1 clusters\n",
      "Cluster 0: 20 points\n",
      "Linearity: 0.6226538346940831 False\n",
      "Theta: 78.68377477041275\n",
      "Eigenvalues: [0.00175863 0.00066361 0.00010517]\n",
      "Eigenvectors: [[ 0.58712014  0.0744662  -0.80606744]\n",
      " [-0.78535734  0.29377216 -0.54489611]\n",
      " [ 0.19622383  0.95297046  0.23096213]]\n",
      "Track count: 0\n"
     ]
    }
   ],
   "source": [
    "i = 40\n",
    "\n",
    "lines = []\n",
    "\n",
    "hood = xyz[indices[i]]\n",
    "if hood.shape[0] < minimum_in_hood:   \n",
    "    raise ValueError(\"Not enough points in neighborhood\") # continue\n",
    "print(f\"Seed point {i} has {hood.shape[0]} points in its neighborhood\")\n",
    "\n",
    "# eigenvals, eigenvects = pca(hood)\n",
    "# linearity_at_seed = linearity(eigenvals)\n",
    "# theta_at_seed = theta(eigenvects)\n",
    "\n",
    "# print(f\"Linearity of {i}: {linearity_at_seed}\")\n",
    "# print(f\"Theta: {theta_at_seed}\")\n",
    "# print(f\"Eigenvalues: {eigenvals}\")\n",
    "# print(f\"Eigenvectors: {eigenvects}\")\n",
    "\n",
    "\n",
    "trackcount = 0\n",
    "# labels = dbscan(hood, eps=0.05, min_points=10)\n",
    "min_points = 10 # hood.shape[0] // 10\n",
    "\n",
    "# labels = dbscan_stretchz(hood, eps=0.05, min_points=min_points, stretch=2)\n",
    "# labels = dbscan_stretchz_noise(hood, eps=0.055, min_points=min_points, stretch=2.5, noise_neighbors=10, noise_std=2.0)\n",
    "# labels = dbscan_stretchz_noise(hood, eps=0.07, min_points=min_points, stretch=3, noise_neighbors=10, noise_std=2.0)\n",
    "# labels = dbscan_stretchz(hood, eps=0.09, min_points=min_points, stretch=5)\n",
    "\n",
    "labels = dbscan_stretchz_auto(hood, min_points=min_points, stretch=4)\n",
    "\n",
    "max_label = labels.max()\n",
    "clustercount = max_label + 1\n",
    "print()\n",
    "print(f\"Found {max_label + 1} clusters\")\n",
    "# print(max_label + 1, \"Clusters\")\n",
    "for label in range(max_label + 1):\n",
    "    cluster = hood[labels == label]\n",
    "    eigenvals, eigenvects = pca(cluster)\n",
    "    cluster_linearity = linearity(eigenvals)\n",
    "    projected = hood @ eigenvects[:,0] # Project on first eigenvector\n",
    "    # Length along first principal component\n",
    "    # lines.append(plot_first_eigenvec(cluster.mean(axis=0), eigenvects))\n",
    "    # print(cluster_linearity, end=\" \")\n",
    "    print(f\"Cluster {label}: {labels[labels == label].shape[0]} points\")\n",
    "    print(f\"Linearity: {cluster_linearity} {cluster_linearity > linearity_tresh}\")\n",
    "    print(f\"Theta: {theta(eigenvects)}\")\n",
    "    print(f\"Eigenvalues: {eigenvals}\")\n",
    "    print(f\"Eigenvectors: {eigenvects}\")\n",
    "    \n",
    "    if cluster_linearity > linearity_tresh:\n",
    "        if eigenvals[0] > 0.02:\n",
    "            trackcount += 1\n",
    "            lines.append(plot_first_eigenvec(cluster.mean(axis=0), eigenvects, stretch=eigenvals[0]*5))\n",
    "        else:\n",
    "            lines.append(plot_first_eigenvec(cluster.mean(axis=0), eigenvects, color=[0, 0, 0.7], stretch=eigenvals[0]*5))\n",
    "    else:\n",
    "        lines.append(plot_first_eigenvec(cluster.mean(axis=0), eigenvects, color=[0, 0, 0], stretch=eigenvals[0]*5))\n",
    "# print(\"\\nTrack count\", trackcount[i])\n",
    "print(f\"Track count: {trackcount}\")\n",
    "# print()\n",
    "\n",
    "colors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\n",
    "colors[labels < 0] = [0.5, 0.5, 0.5, 1] # Farbe für Punkte, die zu keinem Cluster gehören\n",
    "hood_pcd = o3d.geometry.PointCloud()\n",
    "hood_pcd.points = o3d.utility.Vector3dVector(hood)\n",
    "hood_pcd.colors = o3d.utility.Vector3dVector(colors[:,:3])\n",
    "o3d.visualization.draw_geometries([hood_pcd] + lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spread ist irgendwie nicht wie die ursprünglichen Meter. \n",
    "- Typische Werte bei sinnvollen Clustern: 0.28, 0.09\n",
    "- Bei Miniclustern: 0.05, 0.02, 0.01\n",
    "- Sinnvoller direkt die erste Eigenvalue zu nehmen\n",
    "\n",
    "```\n",
    "def pca_spread(points, eigenvals, eigenvects):\n",
    "    \"\"\"Length along first principal component\"\"\"\n",
    "    projected = points @ eigenvects[:,0] # Project on first eigenvector\n",
    "    return (np.max(projected) - np.min(projected)) * np.sqrt(eigenvals[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "points",
   "language": "python",
   "name": "points"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
