{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erste Experimente mit Numba\n",
    "- Voxelfilter: außen parallel, innen nopython\n",
    "- Compilierung 8 s\n",
    "- Dann Laufzeit auf ein Drittel\n",
    "- Worker -1 in kdtree.query lohnt sich (10 mal scheller, von 0.1 zu 0.01)\n",
    "- Jupyter Notebook \n",
    "    - ist laut ChatGPT schon multithreaded\n",
    "    - Keine genaue Vergleichbarkeit mit cpython\n",
    "    - Evtl. dauert Compilierung in Jupyter etwas länger als bei cpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdal \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.linalg import svd \n",
    "import open3d as o3d\n",
    "from osgeo import ogr\n",
    "\n",
    "from numba import jit, njit, prange\n",
    "\n",
    "from interessant import * # Bei Änderungen Kernel neu starten\n",
    "ogr.UseExceptions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viele Gleise 4474750_5332150.copc.laz\n"
     ]
    }
   ],
   "source": [
    "run = run24\n",
    "#run = run14\n",
    "# filename = interessant['OLA gleiche Höhe wie Gleis']\n",
    "\n",
    "# Bahnsteig: 29; Gleis hohe Intensität: 11; Weiche B: 16; Unterirdischer Bhf: 20; Gleis weit abseits: 23; Betondeckel: 28; Zug run 14 A (in run24 Achszähler): 6; \n",
    "# Viele Gleise: 33; Anfang Weiche: 34, OLA gleiche H: 35; Y: 37\n",
    "key = list(interessant.keys())[33] \n",
    "filename = interessant[key]\n",
    "print(key, filename)\n",
    "\n",
    "filename = os.path.join(run, filename)\n",
    "if not os.path.exists(filename):\n",
    "    raise FileNotFoundError(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel size: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "empty_space_thresh = 8  # z.B. 5 oder 8\n",
    "majority_tresh  = 0.5 # Erster Durchgang 0.3, bei \"Gleis hohe Intensität\" gibt 0.5 ein viel besseres Ergebnis\n",
    "ground_percentile = 10 # 10 in Oude E.\n",
    "top_percentile = 99.5 # 90 in Oude E.\n",
    "\n",
    "voxel_size = 1.0\n",
    "\n",
    "voxel_size = 25 / 30\n",
    "print(\"Voxel size:\", voxel_size)\n",
    "\n",
    "minimum_points = 50 # Erste Versuche mit 100, aber viel schwarz bei abseits liegenden Gleisen. 50 ist besser.\n",
    "\n",
    "with_normals = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2289989,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = pdal.Pipeline([pdal.Reader(filename)])\n",
    "pipeline.execute()\n",
    "points = pipeline.arrays[0]\n",
    "\n",
    "points['Classification'] = 0\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity = points['Intensity']\n",
    "intensity_normalized = (intensity - intensity.min()) / (intensity.max() - intensity.min())\n",
    "colormap = plt.get_cmap(\"viridis\")\n",
    "intensity_colors = colormap(intensity_normalized)\n",
    "intensity_colors = intensity_colors[:, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ohne jit: 0.05 s\n",
    "- jit: funktioniert nicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04269814491271973\n"
     ]
    }
   ],
   "source": [
    "# @jit\n",
    "def get_xyz(points):\n",
    "    xyz = np.vstack((points['X'], points['Y'], points['Z'])).transpose()\n",
    "\n",
    "    # Offset entfernen (aber gerundet, damit Kachelgrenzen ganze Zahlen bleiben)\n",
    "    offset = xyz.mean(axis=0).round() \n",
    "    xyz -= offset\n",
    "    return xyz, offset\n",
    "\n",
    "start = time.time()\n",
    "xyz, offset = get_xyz(points)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voxelfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 8.99998766,  5.99997468, 15.44354109]),\n",
       " array([-16.00001234, -18.99982532,   0.10734109]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAIL = 20\n",
    "\n",
    "maxp = xyz.max(axis=0)\n",
    "minp = xyz.min(axis=0)\n",
    "maxp, minp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels = ((xyz[:, :2] - minp[:2]) // voxel_size).astype(int)\n",
    "v_max = voxels.max(axis=0)\n",
    "z = xyz[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktioniert ursprünglich nicht wegen None und try-except"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def check_constraints(z_values):\n",
    "    foo = 0.3  \n",
    "    # Threshold on number of points in voxel\n",
    "    if len(z_values) < minimum_points:\n",
    "        return np.array([False]) # None geht nicht mit Numba njit\n",
    "\n",
    "    ground_level = np.percentile(z_values, ground_percentile) \n",
    "    # 10% Percentile\n",
    "    # Check that there are almost no points 0.5 to 4.5 m above the ground\n",
    "    # But allow for some noise\n",
    "\n",
    "    count = ((z_values > ground_level + foo) & (z_values < ground_level + 4.5)).sum()\n",
    "\n",
    "    if count <= empty_space_thresh:\n",
    "        # Look for points within 0.5 m above ground and get \n",
    "        # 98 percentile (Oude E.) or better 99.5 percentile\n",
    "        mask = (z_values > ground_level) & (z_values < ground_level + foo)\n",
    "        if len(z_values[mask]) == 0:\n",
    "            return np.array([False])\n",
    "        candidates_top = np.percentile(z_values[mask], top_percentile)\n",
    "\n",
    "        # Oude Elberink require the height difference > 0.1 m\n",
    "        # And mark only the points 10 cm below the top as rail point candidates\n",
    "        if candidates_top - ground_level > 0.1:\n",
    "            mask = (z_values > candidates_top - 0.1) & (z_values < candidates_top + 0.05)\n",
    "\n",
    "            # Also make sure these are only a minority of the points (otherwise it's a slope)\n",
    "            if mask.sum() < majority_tresh * len(z_values):  # z.B. 0.3\n",
    "                return mask\n",
    "    return np.array([False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(voxels, z, points, v_max):\n",
    "    for i in range (v_max[0] + 1):\n",
    "        for j in range(v_max[1] + 1):\n",
    "            mask = (voxels[:,0] == i) & (voxels[:,1] == j)\n",
    "            z_values = z[mask]\n",
    "            mask2 = check_constraints(z_values)\n",
    "            if mask2 is not None:\n",
    "                indices = np.where(mask)[0]\n",
    "                points['Classification'][indices[mask2]] = RAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def jitclassify(voxels, z, points, v_max):\n",
    "    for i in prange (v_max[0] + 1):\n",
    "        for j in prange(v_max[1] + 1):\n",
    "            mask = (voxels[:,0] == i) & (voxels[:,1] == j)\n",
    "            z_values = z[mask]\n",
    "            mask2 = check_constraints(z_values)\n",
    "            if mask2 is not np.array([False]):\n",
    "                indices = np.where(mask)[0]\n",
    "                points['Classification'][indices[mask2]] = RAIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ohne jit 3.8, 3.6, 3.9\n",
    "- mit jit, nicht parallel \n",
    "    - erstes mal 4.6; \n",
    "    - dann 3.3, 3.4\n",
    "- parallel: \n",
    "    - erste mal 7.88 oder 4.1!\n",
    "    - dann 1.33, 1.4, 1.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# classify(voxels, z, points, v_max)\n",
    "\n",
    "# end = time.time()\n",
    "# print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.125516414642334\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "jitclassify(voxels, z, points, v_max)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gleispaar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = \"/media/riannek/minimax/gleis/temp_fertig\"\n",
    "\n",
    "filename = interessant[key]\n",
    "filename = filename.split(\".\")[0] + \".ply\"\n",
    "\n",
    "if not os.path.exists(os.path.join(tmpdir, filename)):\n",
    "    raise FileNotFoundError(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_side_distance = 0.15   # 0.1 ist meist gut, aber in manchen Fällen zu wenig (z.B. Anfang Weiche)\n",
    "\n",
    "intensity_threshold = 14500\n",
    "downsample_radius = 0.45 # 0.4\n",
    "neighborhood_radius = 0.5 # 0.5\n",
    "\n",
    "min_points = 10\n",
    "minimum_in_hood = 10\n",
    "linearity_tresh = 0.98\n",
    "\n",
    "gauge = 1.435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpkg = ogr.Open(os.path.join(tmpdir, \"temp.gpkg\"))\n",
    "layer = gpkg.GetLayerByName(\"tiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@njit # Lohnt sich nicht\n",
    "def extend_bbox(bbox, margin=2):\n",
    "    # MinX, MaxX, MinY, MaxY\n",
    "    return (bbox[0] - margin, bbox[1] + margin, bbox[2] - margin, bbox[3] + margin)\n",
    "\n",
    "def get_bbox_polygon(bbox):  \n",
    "    ring = ogr.Geometry(ogr.wkbLinearRing)      \n",
    "    ring.AddPoint_2D(bbox[0], bbox[2])  # MinX, MinY\n",
    "    ring.AddPoint_2D(bbox[1], bbox[2])  # MaxX, MinY\n",
    "    ring.AddPoint_2D(bbox[1], bbox[3])  # MaxX, MaxY\n",
    "    ring.AddPoint_2D(bbox[0], bbox[3])  # MinX, MaxY\n",
    "    ring.AddPoint_2D(bbox[0], bbox[2])  # Close ring\n",
    "    geom = ogr.Geometry(ogr.wkbPolygon)\n",
    "    geom.AddGeometry(ring)\n",
    "    return geom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "njit extend_bbox: \n",
    "- Compile 1 s\n",
    "- Dann 0.003 s\n",
    "Ohne njit genau gleich schnell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4474725_5332175.ply', '4474750_5332175.ply', '4474750_5332125.ply', '4474725_5332150.ply', '4474775_5332125.ply', '4474775_5332150.ply', '4474750_5332150.ply', '4474725_5332125.ply', '4474775_5332175.ply']\n",
      "0.8653550148010254\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "filter = f\"filename = '{filename}'\"\n",
    "layer.SetAttributeFilter(filter)\n",
    "feature = layer.GetNextFeature()\n",
    "layer.SetAttributeFilter(None)\n",
    "bbox = feature.GetGeometryRef().GetEnvelope()\n",
    "extended = extend_bbox(bbox, margin=2)\n",
    "bbox_geom = get_bbox_polygon(extended)\n",
    "layer.SetSpatialFilter(bbox_geom)\n",
    "tiles = [f.GetField(\"filename\") for f in layer]\n",
    "layer.SetSpatialFilter(None) \n",
    "\n",
    "print(tiles) \n",
    "print(time.time()- start)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gpkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'([4474748.0, 4474777.0], [5332148.0, 5332177.0])'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = f\"([{extended[0]}, {extended[1]}], [{extended[2]}, {extended[3]}])\" \n",
    "bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allein das dauert 0.6 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5804653167724609\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "readers = [pdal.Reader(os.path.join(tmpdir, tile)) for tile in tiles]\n",
    "pipeline = pdal.Pipeline(readers) | pdal.Filter.merge() | pdal.Filter.crop(bounds=bounds)\n",
    "pipeline.execute()\n",
    "points = pipeline.arrays[0]\n",
    "points.shape \n",
    "\n",
    "print(time.time()- start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247472,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_intensity = points[points[\"Intensity\"] < intensity_threshold]\n",
    "low_intensity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'([4474750.0, 4474775.0], [5332150.0, 5332175.0])'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = f\"([{bbox[0]}, {bbox[1]}], [{bbox[2]}, {bbox[3]}])\" \n",
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample with poisson sampling (only original bbox)\n",
    "\n",
    "downsampling_pipeline = pdal.Filter.crop(bounds=bounds).pipeline(low_intensity) | pdal.Filter(\"filters.sample\", radius=downsample_radius)\n",
    "downsampling_pipeline.execute()\n",
    "seed_points = downsampling_pipeline.arrays[0]\n",
    "seed_point_count = seed_points.shape[0]\n",
    "seed_point_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KD Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = np.vstack((points['X'], points['Y'], points['Z'])).transpose()\n",
    "xyz_seed = np.vstack((seed_points['X'], seed_points['Y'], seed_points['Z'])).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = xyz.mean(axis=0).round() \n",
    "xyz -= offset\n",
    "xyz_seed -= offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08271336555480957\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tree = KDTree(xyz)  \n",
    "print(time.time()- start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- workers 1 (default) 0.4, 0.6, 0.7\n",
    "- workers -1: 0.03, 0.03, 0.04\n",
    "- lohnt sich!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01767134666442871\n"
     ]
    }
   ],
   "source": [
    "# indices: ndarray (dtype object) with a list of indices for each seed point\n",
    "start = time.time()\n",
    "indices = tree.query_ball_point(xyz_seed, r=neighborhood_radius, workers=-1)\n",
    "print(time.time()- start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(cloud):\n",
    "    \"\"\"Use PCA to get einvalues and eigenvectors of a point cloud\n",
    "    \n",
    "    Returns (eigenvalues, eigenvectors)\n",
    "    \"\"\"\n",
    "    if cloud.shape[0] < 3:\n",
    "        raise ValueError(\"Point cloud must have at least 3 points\")\n",
    "    mean = np.mean(cloud, axis=0)\n",
    "    centered = cloud - mean\n",
    "    U, S, Vt = svd(centered, full_matrices=False)\n",
    "    eigenvals = S**2/(cloud.shape[0]-1)\n",
    "    # Returned vectors are in columns, first vector is eigenvec[:, 0] == eigenvec.T[0]\n",
    "    return eigenvals, Vt.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit(forceobj=True)\n",
    "def dbscan_stretchz(xyz, min_points=10, stretch=1.5):\n",
    "\n",
    "    pointcount = xyz.shape[0]\n",
    "    if pointcount <= min_points:\n",
    "        return np.ones(pointcount, dtype=np.int8) * -1\n",
    "    \n",
    "    eps = 50 / pointcount\n",
    "    eps = max(eps, 0.06)\n",
    "    \n",
    "    xyz = xyz.copy()\n",
    "    xyz[:, 2] *= stretch\n",
    "    hood_pcd = o3d.geometry.PointCloud()\n",
    "    hood_pcd.points = o3d.utility.Vector3dVector(xyz) \n",
    "    # eps is min distance between clusters\n",
    "    labels = np.array(hood_pcd.cluster_dbscan(eps=eps, min_points=min_points, print_progress=False))\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_central_point(a, b):\n",
    "    \"\"\"Get the point in the middle of two points\"\"\"\n",
    "    vector = b - a\n",
    "    return a + vector / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def linearity(eigenvals):\n",
    "    \"\"\"Calculate the linearity of a point cloud\"\"\"\n",
    "    return (eigenvals[0] - eigenvals[1]) / eigenvals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit(forceobj=True, looplift=True)\n",
    "def cluster_generator(points, min_points):\n",
    "    if points.shape[0] < min_points:\n",
    "        return\n",
    "    \n",
    "    labels = dbscan_stretchz(points, min_points=min_points, stretch=4)\n",
    "    \n",
    "    max_label = labels.max()\n",
    "    \n",
    "    for label in range(max_label + 1):\n",
    "        cluster = points[labels == label]\n",
    "        if cluster.shape[0] < min_points:\n",
    "            # Somehow this happens, must be a bug in open3d\n",
    "            continue\n",
    "\n",
    "        eigenvals, eigenvects = pca(cluster)\n",
    "        cluster_linearity = linearity(eigenvals)\n",
    "\n",
    "\n",
    "        if not ((cluster_linearity > linearity_tresh) and (eigenvals[0] > 0.04)):\n",
    "            # Cluster not linear or too short\n",
    "            continue\n",
    "\n",
    "        clustercenter = cluster.mean(axis=0)\n",
    "\n",
    "        # Make sure there are no points above the cluster\n",
    "        # (exclude clusters at the base of the track profile)\n",
    "        if not cluster_is_on_top(cluster, clustercenter, points):\n",
    "            continue\n",
    "        \n",
    "\n",
    "        yield cluster, clustercenter, eigenvals, eigenvects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def cluster_is_on_top(cluster, clustercenter, points):\n",
    "    \"\"\"Check that there are no points above the cluster center\"\"\"\n",
    "    x_min, x_max = clustercenter[0] - 0.1, clustercenter[0] + 0.1\n",
    "    y_min, y_max = clustercenter[1] - 0.1, clustercenter[1] + 0.1\n",
    "    z_min = cluster[:,2].max()\n",
    "\n",
    "    mask = ((points[:, 0] > x_min) & \n",
    "        (points[:, 0] < x_max) & \n",
    "        (points[:, 1] > y_min) & \n",
    "        (points[:, 1] < y_max) & \n",
    "        (points[:, 2] > z_min))\n",
    "    \n",
    "    \n",
    "    return points[mask].shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit(forceobj=True, looplift=True)\n",
    "def check_cluster_for_railpair(clustercenter, eigenvects, pointcloud, tree, gauge, min_points):\n",
    "\n",
    "    # Check for rail pair\n",
    "    sidevector = np.cross(eigenvects[:,0], np.array([0, 0, 1])) * (gauge + 0.07) # Add railtop width to gauge\n",
    "    bothsides = np.array([clustercenter + sidevector, clustercenter - sidevector])\n",
    "\n",
    "    indices_bothsides = tree.query_ball_point(bothsides, r=neighborhood_radius)\n",
    "    \n",
    "    # Linear cluster that is closest to one of the estimated side points (ignoring z)\n",
    "    # but must me within r = 15 cm and almost parallel\n",
    "\n",
    "    closest_cluster_distance = 100000000.0\n",
    "    closest_cluster = None\n",
    "    closest_cluster_center = None\n",
    "    \n",
    "    for j, side in enumerate(indices_bothsides):\n",
    "        for sidecluster, sideclustercenter, _, eigenvects_side in cluster_generator(pointcloud[side], min_points):\n",
    "            \n",
    "            # Check distance\n",
    "            sidecluster_distance = np.linalg.norm(sideclustercenter[:2] - bothsides[j][:2]) # only xy\n",
    "            if sidecluster_distance < thresh_side_distance and sidecluster_distance < closest_cluster_distance:\n",
    "                # Check if parallel\n",
    "                cos_angle = np.abs(np.dot(eigenvects[:,0], eigenvects_side[:,0]))\n",
    "                if cos_angle > 0.9:  \n",
    "                    closest_cluster = sidecluster\n",
    "                    closest_cluster_distance = sidecluster_distance\n",
    "                    closest_cluster_center = sideclustercenter\n",
    "\n",
    "    return closest_cluster, closest_cluster_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ohne: 0.66\n",
    "- linearity und on top\n",
    "    - mit compile 1.16\n",
    "    - dann 0.65\n",
    "- die anderen mit object mode\n",
    "    - mit compile 0.92s\n",
    "    - dann 0.66 (langsamer!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(seed_point_count):\n",
    "    for cluster, clustercenter, eigenvals, eigenvects in cluster_generator(xyz[indices[i]], min_points=min_points):\n",
    "        pass\n",
    "\n",
    "print(f\"Time: {time.time() - start:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_seedpoints(indices, tree, gauge, min_points):\n",
    "    center_points = []\n",
    "    for i in range(seed_point_count):\n",
    "        for cluster, clustercenter, eigenvals, eigenvects in cluster_generator(xyz[indices[i]], min_points=min_points):\n",
    "            pair_cluster, pair_center = check_cluster_for_railpair(clustercenter, eigenvects, xyz, tree, gauge, min_points)\n",
    "            if pair_cluster is not None:\n",
    "                # lines.append(pv.Line(clustercenter, pair_center))\n",
    "                center_points.append(get_central_point(clustercenter, pair_center))\n",
    "    return center_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit(forceobj=True, looplift=True, parallel=True) # Stürzt ab\n",
    "@jit(forceobj=True, parallel=True)\n",
    "def check_seedpoints_numba(indices, tree, gauge, min_points):\n",
    "    center_points = []\n",
    "    for i in prange(seed_point_count):\n",
    "        for cluster, clustercenter, eigenvals, eigenvects in cluster_generator(xyz[indices[i]], min_points=min_points):\n",
    "            pair_cluster, pair_center = check_cluster_for_railpair(clustercenter, eigenvects, xyz, tree, gauge, min_points)\n",
    "            if pair_cluster is not None:\n",
    "                # lines.append(pv.Line(clustercenter, pair_center))\n",
    "                center_points.append(get_central_point(clustercenter, pair_center))\n",
    "    return center_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ohne 1.53 1.39  1.36 1.37\n",
    "- mit stürzt ab!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3784897327423096\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "center_points = check_seedpoints(indices, tree, gauge, min_points)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_555997/3896833041.py:2: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"check_seedpoints_numba\" failed type inference due to: \u001b[1mUntyped global name 'cluster_generator':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'function'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"../../../../../tmp/ipykernel_555997/3896833041.py\", line 6:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit(forceobj=True, parallel=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.836362361907959\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "center_points = check_seedpoints_numba(indices, tree, gauge, min_points)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "points",
   "language": "python",
   "name": "points"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
